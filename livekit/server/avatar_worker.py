#!/usr/bin/env python3
"""
Avatar Worker - Standalone process that generates and publishes avatar video.

This worker:
1. Connects to a LiveKit room using a provided token
2. Receives TTS audio from the agent via DataStream (data channel)
3. Generates synchronized video using SyncTalk's NeRF-based renderer
4. Publishes both audio and video back to the room

The AvatarRunner handles all synchronization automatically.
"""

import asyncio
import logging
import os
import sys
from pathlib import Path

from livekit import rtc
from livekit.agents import utils
from livekit.agents.voice.avatar import (
    AvatarOptions,
    AvatarRunner,
    DataStreamAudioReceiver,
)

# Add parent directories to path for imports
sys.path.insert(0, str(Path(__file__).parent))  # livekit/server/
sys.path.insert(0, str(Path(__file__).parent.parent.parent))  # project root for streaming_inference
# Using SyncTalk for NeRF-based high-quality video generation
from synctalk_video_generator import (
    SyncTalkVideoGenerator,
)

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("avatar-worker")

# --- Configuration from environment variables ---
SYNCTALK_DATA_PATH = os.environ.get("SYNCTALK_DATA_PATH", "data/May")
SYNCTALK_WORKSPACE = os.environ.get("SYNCTALK_WORKSPACE", "model/trial_may")
SYNCTALK_PORTRAIT = os.environ.get("SYNCTALK_PORTRAIT", "true") == "true"
SYNCTALK_TORSO = os.environ.get("SYNCTALK_TORSO", "false") == "true"

AVATAR_WIDTH = int(os.environ.get("AVATAR_WIDTH", "512"))
AVATAR_HEIGHT = int(os.environ.get("AVATAR_HEIGHT", "512"))
AVATAR_FPS = int(os.environ.get("AVATAR_FPS", "25"))


@utils.log_exceptions(logger=logger)
async def main(api_url: str, api_token: str):
    """
    Main avatar worker function.

    Args:
        api_url: LiveKit server URL (from LIVEKIT_URL env var)
        api_token: Access token for the avatar worker (generated by agent)
    """
    logger.info(f"Avatar worker starting...")
    logger.info(f"Connecting to: {api_url}")
    logger.info(f"SyncTalk config:")
    logger.info(f"  Data Path: {SYNCTALK_DATA_PATH}")
    logger.info(f"  Workspace: {SYNCTALK_WORKSPACE}")
    logger.info(f"  Portrait: {SYNCTALK_PORTRAIT}")
    logger.info(f"  Torso: {SYNCTALK_TORSO}")
    logger.info(f"  Resolution: {AVATAR_WIDTH}x{AVATAR_HEIGHT} @ {AVATAR_FPS}fps")

    # Define avatar options
    avatar_options = AvatarOptions(
        video_width=AVATAR_WIDTH,
        video_height=AVATAR_HEIGHT,
        video_fps=AVATAR_FPS,
        audio_sample_rate=16000,  # SyncTalk requires 16kHz
        audio_channels=1,  # Mono
    )

    # Create SyncTalk video generator
    logger.info("Initializing SyncTalk video generator...")
    video_gen = SyncTalkVideoGenerator(
        data_path=SYNCTALK_DATA_PATH,
        workspace=SYNCTALK_WORKSPACE,
        portrait=SYNCTALK_PORTRAIT,
        torso=SYNCTALK_TORSO,
        video_width=AVATAR_WIDTH,
        video_height=AVATAR_HEIGHT,
        video_fps=AVATAR_FPS,
    )

    # Connect to the room
    room = rtc.Room()
    await room.connect(api_url, api_token)
    logger.info(f"✅ Connected to room: {room.name}")

    should_stop = asyncio.Event()

    # Stop when agent disconnects or room disconnects
    @room.on("participant_disconnected")
    def _on_participant_disconnected(participant: rtc.RemoteParticipant):
        if participant.kind == rtc.ParticipantKind.PARTICIPANT_KIND_AGENT:
            logger.info(
                f"Agent {participant.identity} disconnected, stopping avatar worker"
            )
            should_stop.set()

    @room.on("disconnected")
    def _on_disconnected():
        logger.info("Room disconnected, stopping avatar worker")
        should_stop.set()

    # Create avatar runner with DataStream audio receiver
    logger.info("Creating AvatarRunner...")
    runner = AvatarRunner(
        room,
        audio_recv=DataStreamAudioReceiver(room),
        video_gen=video_gen,
        options=avatar_options,
        _queue_size_ms=500,  # Larger queue for smoother handling of TTS bursts (default: 100ms)
    )

    try:
        # Start the video generator's background processor
        await video_gen.start()
        logger.info("✅ Video generator background processor started")
        
        # Start the avatar runner
        await runner.start()
        logger.info("✅ Avatar runner started - ready to receive audio from agent")

        # Run until stopped or the runner completes/fails
        tasks = [
            asyncio.create_task(runner.wait_for_complete()),
            asyncio.create_task(should_stop.wait()),
        ]
        done, pending = await asyncio.wait(tasks, return_when=asyncio.FIRST_COMPLETED)

        # Check if runner failed
        for task in done:
            if task.exception():
                logger.error(f"Task failed with exception: {task.exception()}")

    finally:
        # Cleanup
        logger.info("Shutting down avatar worker...")
        await utils.aio.cancel_and_wait(*tasks)
        await video_gen.aclose()
        await runner.aclose()
        await room.disconnect()
        logger.info("✅ Avatar worker stopped")


if __name__ == "__main__":
    from livekit.agents.cli.log import setup_logging

    setup_logging("INFO", devmode=True, console=True)

    # Get connection info from environment variables
    livekit_url = os.getenv("LIVEKIT_URL")
    livekit_token = os.getenv("LIVEKIT_TOKEN")

    if not livekit_url or not livekit_token:
        logger.error("❌ LIVEKIT_URL and LIVEKIT_TOKEN must be set")
        logger.error("These are set automatically by the agent worker")
        sys.exit(1)

    # Run the avatar worker
    asyncio.run(main(livekit_url, livekit_token))
